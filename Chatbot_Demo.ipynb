{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b89324-576c-4a25-ab50-87b17c1fcacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fed3b9-0333-419a-8534-a0126dcff394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(system_message: str, user_message: str):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef3b23c-7143-4197-bd2e-4f663693e272",
   "metadata": {},
   "source": [
    "# Basic chatbot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e71ff7-a171-400b-8dc8-bc0bd111e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message =  \"You are a helpful assistant.\"\n",
    "user_message = \"How do I reset a Zoom Room tablet?\"\n",
    "\n",
    "messages = build_prompt(system_message, user_message)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb953830-9586-46ee-8fb7-d94f71d36c7b",
   "metadata": {},
   "source": [
    "# Using system instructions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a9562a-c307-4a9f-8ae3-06e105dab290",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an internal IT helpdesk bot. Always ask for the room name and device ID before giving troubleshooting advice.\"\n",
    "user_message = \"The screen in my conference room isn't turning on.\"\n",
    "\n",
    "messages = build_prompt(system_message, user_message)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa2590-2851-4ce4-b402-bd3f5f7806f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"Sure, I am in room 210 using screen A15.\"\n",
    "\n",
    "messages = build_prompt(system_message, user_message)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2927cf52-b20c-4edd-b527-db92d9f6b94a",
   "metadata": {},
   "source": [
    "### The OpenAI API is stateless, so need to append the entire conversation to create a continuous thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6facd95d-e5a9-4b92-9689-d15240682cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatSession:\n",
    "    def __init__(self, system_prompt: str, model: str = \"gpt-4o\", api_key: str = None):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.model = model\n",
    "        self.messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    \n",
    "    def send(self, user_input: str, temperature: float = 0.7) -> str:\n",
    "        '''iterative chat send'''\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=self.messages,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        assistant_reply = response.choices[0].message.content\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "        return assistant_reply\n",
    "    \n",
    "    def reset(self, new_system_prompt: str = None):\n",
    "        if new_system_prompt:\n",
    "            self.messages = [{\"role\": \"system\", \"content\": new_system_prompt}]\n",
    "        else:\n",
    "            self.messages = self.messages[:1]  # keep original system prompt only\n",
    "    \n",
    "    def show_history(self):\n",
    "        return self.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c0937a-a7d9-4233-ac61-dbff94a4a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = ChatSession(\n",
    "    system_prompt=\"You are an internal IT helpdesk bot. Always ask for the room name and device ID before giving troubleshooting advice.\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb807d96-a17a-4ed6-9985-38866cbe4819",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply1 = session.send(\"The screen in my conference room isn't turning on.\")\n",
    "print(\"Assistant:\", reply1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d8a7df-3770-42aa-b875-ed45f370059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply2 = session.send(\"It's Room 3A. The device ID is ZR3A-0093.\")\n",
    "print(\"Assistant:\", reply2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81671d09-454d-4aa6-bf50-8842bfc3b8be",
   "metadata": {},
   "source": [
    "# Integrating RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac399c85-db04-4008-a1c4-62c8174aff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "docs = [\n",
    "    \"If a Zoom Room tablet is unresponsive, hold the power button for 10 seconds to restart it.\",\n",
    "    \"To reset a Cisco conferencing camera, unplug it for 30 seconds then plug it back in.\",\n",
    "    \"To file a support ticket, go to go/support and click 'Report AV Issue'.\"\n",
    "]\n",
    "\n",
    "# vector store creates an embedded representation of the docs\n",
    "vectorstore = FAISS.from_texts(docs, OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# first use the \"retriever\" to match embedded docs to the user message\n",
    "user_message = \"How can I fix a frozen Zoom Room screen?\"\n",
    "context_docs = retriever.invoke(user_message)\n",
    "context = \"\\n\".join(doc.page_content for doc in context_docs)\n",
    "\n",
    "# then feed this matched documentation to provide to the chatbot as additional context in the system message\n",
    "system_message = f\"You are a helpdesk assistant. Use the following context to answer user questions:\\n\\n{context}\"\n",
    "session = ChatSession(system_message, api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "response = session.send(user_message)\n",
    "print(\"Assistant:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7804c118-6dc2-4f19-9df6-f2196bb514ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, TextLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# load and format RAG docs\n",
    "loader = DirectoryLoader(\"RAG_docs\", glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "raw_docs = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(raw_docs)\n",
    "\n",
    "# create vector store of doc embeddings\n",
    "vectorstore = FAISS.from_documents(chunks, OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# retrieve relevant documentation\n",
    "query = \"Where should I go to report a problem with the AV system?\"\n",
    "context_docs = retriever.get_relevant_documents(query)\n",
    "context = \"\\n\".join(doc.page_content for doc in context_docs)\n",
    "\n",
    "# start chatbot session with query and retrieved context\n",
    "system_msg = f\"You are a company helpdesk bot. Use the following context to answer the user's question accurately:\\n\\n{context}\"\n",
    "session = ChatSession(system_msg, api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "response = session.send(query)\n",
    "print(\"Assistant:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a0930-1070-48ad-9272-aadb1e64b9d0",
   "metadata": {},
   "source": [
    "# Generate Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4423a926-ad79-4360-8c6a-98b5d9040bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keywords_with_llm(query: str, reply: str, api_key: str, model: str = \"gpt-4o\") -> list[str]:    \n",
    "    keyword_prompt = (\n",
    "        \"You are an AI assistant that extracts relevant keywords from helpdesk queries and responses.\\n\"\n",
    "        \"Return a comma-separated list of 3 to 5 keywords.\\n\\n\"\n",
    "        f\"Query: {query}\\n\\n\"\n",
    "        f\"Response: {reply}\\n\\n\"\n",
    "        \"Keywords:\"\n",
    "    )\n",
    "\n",
    "    session = ChatSession(system_prompt=\"You extract helpful keywords from text.\", model=model, api_key=api_key)\n",
    "    keyword_string = session.send(keyword_prompt)\n",
    "    return [kw.strip() for kw in keyword_string.split(\",\") if kw.strip()]\n",
    "\n",
    "\n",
    "def create_ticket(user_query: str, assistant_reply: str, context_snippets: list[str], keywords: list[str]) -> dict:\n",
    "    return {\n",
    "        \"summary\": user_query,\n",
    "        \"response\": assistant_reply,\n",
    "        \"context_used\": context_snippets,\n",
    "        \"status\": \"open\",\n",
    "        \"created_by\": \"RAG-bot\",\n",
    "        \"category\": \"AV Support\",\n",
    "        \"keywords\": keywords\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2f1ae2-b28b-40bb-b2b9-f9b98410dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Where should I go to report a problem with the AV system?\"\n",
    "context_docs = retriever.invoke(query)\n",
    "context_snippets = [doc.page_content for doc in context_docs]\n",
    "context = \"\\n\".join(context_snippets)\n",
    "\n",
    "system_msg = f\"You are a company helpdesk bot. Use the following context to answer the user's question accurately:\\n\\n{context}\"\n",
    "session = ChatSession(system_msg, api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "assistant_reply = session.send(query)\n",
    "\n",
    "#generate keywords\n",
    "keywords = generate_keywords_with_llm(query, assistant_reply, api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "ticket = create_ticket(query, assistant_reply, context, keywords)\n",
    "\n",
    "# Show results\n",
    "print(\"Assistant:\", assistant_reply)\n",
    "print(\"\\n Ticket Created:\")\n",
    "for key, value in ticket.items():\n",
    "    print(f\"{key.upper()}:\\n{value}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917a0202-f64c-44f1-bddc-4ca74b2e1a8d",
   "metadata": {},
   "source": [
    "# More complete example\n",
    "\n",
    "#### Includes:\n",
    "- Keyword logic to recognize different types of user queries\n",
    "- Ongoing RAG capability\n",
    "- End of conversation behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daaa6a8-3447-45ac-96dd-fa90d2a98e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "from langchain.schema import BaseRetriever\n",
    "\n",
    "class ChatSession:\n",
    "    def __init__(self, system_prompt: str, retriever: BaseRetriever = None, model: str = \"gpt-4o\", api_key: str = None):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.model = model\n",
    "        self.api_key = api_key\n",
    "        self.retriever = retriever\n",
    "        self.is_active = True\n",
    "        self.start_time = datetime.now()\n",
    "        self.messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "        self.retrieval_log = []  # store RAG context per turn if used\n",
    "\n",
    "    def handle_input(self, user_input: str, retriever=None, temperature: float = 0.7) -> str:\n",
    "        '''logic for using RAG and ending the session--hard coded'''\n",
    "        input_lower = user_input.lower()\n",
    "\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        \n",
    "        # check for language indicating the end of the session\n",
    "        if any(phrase in input_lower for phrase in [\"that's all\", \"end session\", \"you can close this\", \"goodbye\", \"bye\", \"that's it\"]):\n",
    "            ticket = self.end()\n",
    "            print(\"📄 Ticket Generated:\\n\")\n",
    "            for k, v in ticket.items():\n",
    "                print(f\"{k.upper()}:\\n{v}\\n\")\n",
    "            return \"Session ended and ticket created.\"\n",
    "    \n",
    "        # check for language indicating that RAG should be used\n",
    "        use_rag = self.retriever is not None and any(kw in input_lower for kw in [\"lookup\", \"look up\", \"reference\", \"context\", \"support\", \"reset\", \"fix\", \"how do i\"])\n",
    "        \n",
    "        if use_rag:\n",
    "            return self.send_with_rag(user_input, temperature=temperature)\n",
    "        else:\n",
    "            return self.send(user_input, temperature=temperature)\n",
    "\n",
    "    def send(self, user_input: str, temperature: float = 0.7) -> str:\n",
    "        '''iterative chat send'''\n",
    "        if not self.is_active:\n",
    "            raise RuntimeError(\"This session has ended.\")\n",
    "            \n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=self.messages,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        assistant_reply = response.choices[0].message.content\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "        return assistant_reply\n",
    "\n",
    "    def send_with_rag(self, user_query: str, temperature: float = 0.7, include_context: bool = True) -> str:\n",
    "        '''iterative chat with RAG lookup'''\n",
    "        if not self.is_active:\n",
    "            raise RuntimeError(\"This session has ended.\")\n",
    "\n",
    "        if include_context:\n",
    "            context_docs = self.retriever.invoke(user_query)\n",
    "            context = \"\\n\".join(doc.page_content for doc in context_docs)\n",
    "            self.retrieval_log.append({\"query\": user_query, \"context\": context})\n",
    "            modified_query = f\"Context:\\n{context}\\n\\nQuestion:\\n{user_query}\"\n",
    "        else:\n",
    "            modified_query = user_query\n",
    "\n",
    "        return self.send(modified_query, temperature=temperature)\n",
    "\n",
    "    def reset(self, new_system_prompt: str = None):\n",
    "        if new_system_prompt:\n",
    "            self.messages = [{\"role\": \"system\", \"content\": new_system_prompt}]\n",
    "        else:\n",
    "            self.messages = self.messages[:1]\n",
    "        self.is_active = True\n",
    "\n",
    "    def show_history(self):\n",
    "        return self.messages\n",
    "\n",
    "    def end(self, generate_ticket: bool = True, use_llm_keywords: bool = True) -> dict:\n",
    "        '''end session and generate ticket'''\n",
    "        self.is_active = False\n",
    "    \n",
    "        if not generate_ticket:\n",
    "            return {}\n",
    "    \n",
    "        # combine entire conversation history\n",
    "        conversation_pairs = [\n",
    "            (self.messages[i][\"content\"], self.messages[i+1][\"content\"])\n",
    "            for i in range(1, len(self.messages)-1, 2)\n",
    "            if self.messages[i][\"role\"] == \"user\" and self.messages[i+1][\"role\"] == \"assistant\"\n",
    "        ]\n",
    "    \n",
    "        # use initial query and response for \"headline\" summary\n",
    "        user_query = conversation_pairs[0][0] if conversation_pairs else \"\"\n",
    "        assistant_reply = conversation_pairs[0][1] if conversation_pairs else \"\"\n",
    "    \n",
    "        # include all RAG context\n",
    "        context_snippets = [r[\"context\"] for r in self.retrieval_log]\n",
    "    \n",
    "        # generate keywords\n",
    "        if use_llm_keywords:\n",
    "            keywords = generate_keywords_with_llm(user_query, assistant_reply, api_key=self.api_key, model=self.model)\n",
    "    \n",
    "        ticket = {\n",
    "            \"headline\": {\n",
    "                \"question\": user_query,\n",
    "                \"answer\": assistant_reply,\n",
    "            },\n",
    "            \"keywords\": keywords,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"turns\": len([m for m in self.messages if m[\"role\"] == \"user\"]),\n",
    "            \"full_conversation\": self.messages,\n",
    "            \"rag_context_log\": self.retrieval_log\n",
    "        }\n",
    "        return ticket\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0594db9-707e-45cb-8b96-39844c5ba5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ChatSession(\n",
    "    system_prompt=\"You are an AV helpdesk bot. Use context when needed. Ask the user if they need anything else at the end of each response.\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "# Simulate dialogue\n",
    "print(\"Assistant:\", s.handle_input(\"How do I reset a Zoom Room controller?\"))\n",
    "print(\"Assistant:\", s.handle_input(\"Can you look up what to do if that doesn't fix the black screen?\"))\n",
    "print(s.handle_input(\"That's all, thank you.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea6dff-a1e6-408a-8a88-2f68cc86103c",
   "metadata": {},
   "source": [
    "### Other possible additions:\n",
    "- LLM logic to route queries (RAG, session end, live human?)\n",
    "- Ability to submit open ticket\n",
    "- Guardrails\n",
    "- ??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
